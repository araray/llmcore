# src/llmcore/agents/sandbox/output_tracker.py
"""
Output Tracking System for Sandbox Agent Runs.

This module provides comprehensive tracking of all outputs generated by
agent runs, including:
    - Agent outputs (files, code, etc.)
    - Execution logs and metadata
    - Lineage tracking for future evolutionary features

Directory Structure:
    {outputs_base}/{agent_run_id}/
    ├── metadata.json          # Run metadata and configuration
    ├── outputs/               # Files produced by the agent
    │   ├── ...               # Any files saved to output mount
    ├── logs/                  # Execution logs
    │   ├── execution.log     # Command execution history
    │   └── agent.log         # Agent cognitive cycle logs
    └── state/                 # Preserved ephemeral state
        └── final_state.json  # Exported state at completion

Usage:
    >>> tracker = OutputTracker(base_path="~/.llmcore/agent_outputs")
    >>> run_id = await tracker.create_run(
    ...     config=sandbox_config,
    ...     metadata={"task": "code_review"}
    ... )
    >>> await tracker.log_execution(run_id, "execute_shell", "ls -la", result)
    >>> await tracker.finalize_run(run_id, sandbox, success=True)
"""

import json
import logging
import shutil
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import TYPE_CHECKING, Any, Dict, List, Optional

if TYPE_CHECKING:
    from .base import ExecutionResult, SandboxProvider

logger = logging.getLogger(__name__)


@dataclass
class ExecutionLog:
    """
    Log entry for a single execution within an agent run.

    Attributes:
        timestamp: When the execution occurred
        tool_name: Name of the tool executed
        input_summary: Truncated input for reference
        exit_code: Exit code of the execution
        execution_time: Time taken in seconds
        success: Whether execution was successful
        output_preview: First 500 chars of output
    """

    timestamp: datetime
    tool_name: str
    input_summary: str
    exit_code: int
    execution_time: float
    success: bool
    output_preview: str

    def to_dict(self) -> dict[str, Any]:
        """Serialize to dictionary."""
        return {
            "timestamp": self.timestamp.isoformat(),
            "tool_name": self.tool_name,
            "input_summary": self.input_summary,
            "exit_code": self.exit_code,
            "execution_time": self.execution_time,
            "success": self.success,
            "output_preview": self.output_preview,
        }


@dataclass
class RunMetadata:
    """
    Metadata for an agent run.

    Attributes:
        run_id: Unique identifier for the run
        created_at: When the run was created
        completed_at: When the run completed (if finished)
        sandbox_type: Type of sandbox used (docker/vm)
        access_level: Sandbox access level
        status: Current run status
        task_description: Optional description of the task
        custom_metadata: Additional user-provided metadata
        execution_count: Number of executions performed
        total_execution_time: Total execution time in seconds
        success: Whether the run succeeded
        error_message: Error message if failed
    """

    run_id: str
    created_at: datetime
    completed_at: datetime | None = None
    sandbox_type: str = "unknown"
    access_level: str = "restricted"
    status: str = "created"
    task_description: str = ""
    custom_metadata: dict[str, Any] = field(default_factory=dict)
    execution_count: int = 0
    total_execution_time: float = 0.0
    success: bool | None = None
    error_message: str = ""

    def to_dict(self) -> dict[str, Any]:
        """Serialize to dictionary."""
        return {
            "run_id": self.run_id,
            "created_at": self.created_at.isoformat(),
            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
            "sandbox_type": self.sandbox_type,
            "access_level": self.access_level,
            "status": self.status,
            "task_description": self.task_description,
            "custom_metadata": self.custom_metadata,
            "execution_count": self.execution_count,
            "total_execution_time": self.total_execution_time,
            "success": self.success,
            "error_message": self.error_message,
        }


class OutputTracker:
    """
    Tracks and persists outputs from agent runs.

    This class manages the output directory structure for agent runs,
    providing methods to:
        - Create new run directories
        - Log executions
        - Track output files
        - Preserve final state
        - Query historical runs

    All data is persisted to the filesystem for durability and
    later analysis.

    Example:
        >>> tracker = OutputTracker()
        >>> run_id = await tracker.create_run(
        ...     sandbox_id="abc123",
        ...     sandbox_type="docker",
        ...     metadata={"task": "code_review"}
        ... )
        >>>
        >>> # During execution
        >>> await tracker.log_execution(run_id, "execute_shell", "ls", result)
        >>> await tracker.track_file(run_id, "output.py", 1024, "Generated code")
        >>>
        >>> # After completion
        >>> await tracker.finalize_run(run_id, sandbox, success=True)
    """

    def __init__(
        self,
        base_path: str = "~/.llmcore/agent_outputs",
        max_log_entries: int = 10000,
        log_input_preview_length: int = 200,
        log_output_preview_length: int = 500,
    ):
        """
        Initialize the output tracker.

        Args:
            base_path: Base directory for all output storage
            max_log_entries: Maximum execution log entries per run
            log_input_preview_length: Max chars for input preview
            log_output_preview_length: Max chars for output preview
        """
        self._base_path = Path(base_path).expanduser().resolve()
        self._max_log_entries = max_log_entries
        self._input_preview_length = log_input_preview_length
        self._output_preview_length = log_output_preview_length

        # Ensure base directory exists
        self._base_path.mkdir(parents=True, exist_ok=True)

        # In-memory cache for active runs
        self._active_runs: dict[str, RunMetadata] = {}
        self._execution_logs: dict[str, list[ExecutionLog]] = {}

        logger.debug(f"OutputTracker initialized: {self._base_path}")

    def _get_run_path(self, run_id: str) -> Path:
        """Get the directory path for a run."""
        return self._base_path / run_id

    def _get_outputs_path(self, run_id: str) -> Path:
        """Get the outputs directory path for a run."""
        return self._get_run_path(run_id) / "outputs"

    def _get_logs_path(self, run_id: str) -> Path:
        """Get the logs directory path for a run."""
        return self._get_run_path(run_id) / "logs"

    def _get_state_path(self, run_id: str) -> Path:
        """Get the state directory path for a run."""
        return self._get_run_path(run_id) / "state"

    async def create_run(
        self,
        sandbox_id: str,
        sandbox_type: str = "unknown",
        access_level: str = "restricted",
        task_description: str = "",
        metadata: dict[str, Any] | None = None,
    ) -> str:
        """
        Create a new run tracking directory.

        Args:
            sandbox_id: ID of the associated sandbox
            sandbox_type: Type of sandbox (docker/vm)
            access_level: Sandbox access level
            task_description: Description of the task
            metadata: Additional custom metadata

        Returns:
            Run ID (same as sandbox_id for correlation)
        """
        run_id = sandbox_id
        run_path = self._get_run_path(run_id)

        # Create directory structure
        run_path.mkdir(parents=True, exist_ok=True)
        self._get_outputs_path(run_id).mkdir(exist_ok=True)
        self._get_logs_path(run_id).mkdir(exist_ok=True)
        self._get_state_path(run_id).mkdir(exist_ok=True)

        # Create metadata
        run_metadata = RunMetadata(
            run_id=run_id,
            created_at=datetime.utcnow(),
            sandbox_type=sandbox_type,
            access_level=access_level,
            status="running",
            task_description=task_description,
            custom_metadata=metadata or {},
        )

        # Store in memory
        self._active_runs[run_id] = run_metadata
        self._execution_logs[run_id] = []

        # Write initial metadata
        await self._write_metadata(run_id)

        logger.info(f"Created output tracking for run: {run_id[:8]}")

        return run_id

    async def _write_metadata(self, run_id: str) -> None:
        """Write metadata to disk."""
        metadata = self._active_runs.get(run_id)
        if metadata:
            metadata_path = self._get_run_path(run_id) / "metadata.json"
            with open(metadata_path, "w") as f:
                json.dump(metadata.to_dict(), f, indent=2)

    async def log_execution(
        self, run_id: str, tool_name: str, input_data: str, result: "ExecutionResult"
    ) -> None:
        """
        Log an execution event.

        Args:
            run_id: Run ID
            tool_name: Name of the tool executed
            input_data: Input to the tool (command/code)
            result: Execution result
        """
        if run_id not in self._execution_logs:
            self._execution_logs[run_id] = []

        # Create log entry
        entry = ExecutionLog(
            timestamp=datetime.utcnow(),
            tool_name=tool_name,
            input_summary=input_data[: self._input_preview_length],
            exit_code=result.exit_code,
            execution_time=result.execution_time_seconds,
            success=result.success,
            output_preview=result.stdout[: self._output_preview_length] if result.stdout else "",
        )

        # Add to in-memory list
        logs = self._execution_logs[run_id]
        if len(logs) < self._max_log_entries:
            logs.append(entry)

        # Update metadata
        if run_id in self._active_runs:
            self._active_runs[run_id].execution_count += 1
            self._active_runs[run_id].total_execution_time += result.execution_time_seconds

        # Append to log file
        log_file = self._get_logs_path(run_id) / "execution.log"
        with open(log_file, "a") as f:
            f.write(json.dumps(entry.to_dict()) + "\n")

    async def get_execution_logs(self, run_id: str) -> list[dict[str, Any]]:
        """
        Get execution logs for a run.

        Args:
            run_id: Run ID

        Returns:
            List of execution log entries as dictionaries
        """
        logs = self._execution_logs.get(run_id, [])
        return [log.to_dict() for log in logs]

    async def get_tracked_files(self, run_id: str) -> list[dict[str, Any]]:
        """
        Get tracked files for a run.

        Args:
            run_id: Run ID

        Returns:
            List of tracked file entries
        """
        manifest_path = self._get_run_path(run_id) / "file_manifest.json"
        if manifest_path.exists():
            with open(manifest_path) as f:
                return json.load(f)
        return []

    async def log_agent_event(
        self, run_id: str, level: str, message: str, data: dict[str, Any] | None = None
    ) -> None:
        """
        Log an agent cognitive cycle event.

        Args:
            run_id: Run ID
            level: Log level (DEBUG, INFO, WARNING, ERROR)
            message: Log message
            data: Optional additional data
        """
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": level.upper(),
            "message": message,
            "data": data,
        }

        log_file = self._get_logs_path(run_id) / "agent.log"
        with open(log_file, "a") as f:
            f.write(json.dumps(log_entry) + "\n")

    async def track_file(
        self, run_id: str, file_path: str, size_bytes: int, description: str = ""
    ) -> None:
        """
        Track a file created by the agent.

        This adds the file to a manifest for later reference.

        Args:
            run_id: Run ID
            file_path: Path to the file (relative to outputs)
            size_bytes: File size
            description: Description of the file
        """
        manifest_path = self._get_run_path(run_id) / "file_manifest.json"

        # Load existing manifest
        manifest = []
        if manifest_path.exists():
            with open(manifest_path) as f:
                manifest = json.load(f)

        # Add entry
        manifest.append(
            {
                "path": file_path,
                "size_bytes": size_bytes,
                "description": description,
                "tracked_at": datetime.utcnow().isoformat(),
            }
        )

        # Write back
        with open(manifest_path, "w") as f:
            json.dump(manifest, f, indent=2)

    async def copy_output_from_sandbox(
        self,
        run_id: str,
        sandbox: "SandboxProvider",
        sandbox_path: str,
        local_filename: str | None = None,
    ) -> bool:
        """
        Copy a file from sandbox to output tracking.

        Args:
            run_id: Run ID
            sandbox: Sandbox provider
            sandbox_path: Path in sandbox
            local_filename: Optional local filename (defaults to basename)

        Returns:
            True if successful
        """
        content = await sandbox.read_file(sandbox_path)
        if content is None:
            return False

        filename = local_filename or Path(sandbox_path).name
        output_path = self._get_outputs_path(run_id) / filename

        with open(output_path, "w") as f:
            f.write(content)

        await self.track_file(run_id, filename, len(content.encode()))
        return True

    async def copy_binary_from_sandbox(
        self,
        run_id: str,
        sandbox: "SandboxProvider",
        sandbox_path: str,
        local_filename: str | None = None,
    ) -> bool:
        """
        Copy a binary file from sandbox to output tracking.

        Args:
            run_id: Run ID
            sandbox: Sandbox provider
            sandbox_path: Path in sandbox
            local_filename: Optional local filename

        Returns:
            True if successful
        """
        content = await sandbox.read_file_binary(sandbox_path)
        if content is None:
            return False

        filename = local_filename or Path(sandbox_path).name
        output_path = self._get_outputs_path(run_id) / filename

        with open(output_path, "wb") as f:
            f.write(content)

        await self.track_file(run_id, filename, len(content))
        return True

    async def save_final_state(self, run_id: str, state: dict[str, Any]) -> None:
        """
        Save the final ephemeral state from the sandbox.

        Args:
            run_id: Run ID
            state: State dictionary to save
        """
        state_path = self._get_state_path(run_id) / "final_state.json"
        with open(state_path, "w") as f:
            json.dump(state, f, indent=2)

    async def finalize_run(
        self,
        run_id: str,
        sandbox: Optional["SandboxProvider"] = None,
        success: bool = True,
        error_message: str = "",
        preserve_state: bool = True,
    ) -> None:
        """
        Finalize a run, preserving outputs and state.

        This should be called before sandbox cleanup to preserve
        any important data.

        Args:
            run_id: Run ID
            sandbox: Optional sandbox to extract state from
            success: Whether the run succeeded
            error_message: Error message if failed
            preserve_state: Whether to preserve ephemeral state
        """
        if run_id in self._active_runs:
            metadata = self._active_runs[run_id]
            metadata.completed_at = datetime.utcnow()
            metadata.status = "completed" if success else "failed"
            metadata.success = success
            metadata.error_message = error_message

            # Write final metadata
            await self._write_metadata(run_id)

            # Write execution logs summary
            await self._write_execution_summary(run_id)

            # Remove from active
            del self._active_runs[run_id]
            del self._execution_logs[run_id]

        # Preserve ephemeral state if sandbox available
        if preserve_state and sandbox:
            try:
                from .ephemeral import EphemeralResourceManager

                ephemeral = EphemeralResourceManager(sandbox)
                state = await ephemeral.export_state()
                await self.save_final_state(run_id, state)
            except Exception as e:
                logger.warning(f"Failed to preserve ephemeral state: {e}")

        logger.info(f"Finalized run: {run_id[:8]} (success={success})")

    async def _write_execution_summary(self, run_id: str) -> None:
        """Write execution logs summary."""
        logs = self._execution_logs.get(run_id, [])

        summary_path = self._get_logs_path(run_id) / "execution_summary.json"
        summary = {
            "total_executions": len(logs),
            "successful": sum(1 for log in logs if log.success),
            "failed": sum(1 for log in logs if not log.success),
            "total_time": sum(log.execution_time for log in logs),
            "by_tool": {},
        }

        for log in logs:
            if log.tool_name not in summary["by_tool"]:
                summary["by_tool"][log.tool_name] = {
                    "count": 0,
                    "success": 0,
                    "failed": 0,
                    "total_time": 0,
                }
            tool_summary = summary["by_tool"][log.tool_name]
            tool_summary["count"] += 1
            tool_summary["total_time"] += log.execution_time
            if log.success:
                tool_summary["success"] += 1
            else:
                tool_summary["failed"] += 1

        with open(summary_path, "w") as f:
            json.dump(summary, f, indent=2)

    async def get_run_metadata(self, run_id: str) -> dict[str, Any] | None:
        """
        Get metadata for a run.

        Args:
            run_id: Run ID

        Returns:
            Metadata dictionary or None if not found
        """
        # Check active runs first
        if run_id in self._active_runs:
            return self._active_runs[run_id].to_dict()

        # Check disk
        metadata_path = self._get_run_path(run_id) / "metadata.json"
        if metadata_path.exists():
            with open(metadata_path) as f:
                return json.load(f)

        return None

    async def list_runs(
        self, limit: int = 100, status_filter: str | None = None
    ) -> list[dict[str, Any]]:
        """
        List tracked runs.

        Args:
            limit: Maximum runs to return
            status_filter: Optional status filter

        Returns:
            List of run metadata dictionaries
        """
        runs = []

        for run_dir in sorted(self._base_path.iterdir(), reverse=True):
            if not run_dir.is_dir():
                continue

            metadata_path = run_dir / "metadata.json"
            if not metadata_path.exists():
                continue

            with open(metadata_path) as f:
                metadata = json.load(f)

            if status_filter and metadata.get("status") != status_filter:
                continue

            runs.append(metadata)

            if len(runs) >= limit:
                break

        return runs

    async def delete_run(self, run_id: str) -> bool:
        """
        Delete a run and all its data.

        Args:
            run_id: Run ID to delete

        Returns:
            True if deleted
        """
        run_path = self._get_run_path(run_id)

        if run_path.exists():
            shutil.rmtree(run_path)

            # Remove from active if present
            self._active_runs.pop(run_id, None)
            self._execution_logs.pop(run_id, None)

            logger.info(f"Deleted run: {run_id[:8]}")
            return True

        return False

    async def get_run_outputs_path(self, run_id: str) -> Path | None:
        """
        Get the outputs directory path for a run.

        Args:
            run_id: Run ID

        Returns:
            Path to outputs directory or None if run doesn't exist
        """
        outputs_path = self._get_outputs_path(run_id)
        if outputs_path.exists():
            return outputs_path
        return None

    async def cleanup_old_runs(self, max_age_days: int = 30, keep_min_runs: int = 10) -> int:
        """
        Clean up old run data.

        Args:
            max_age_days: Delete runs older than this
            keep_min_runs: Always keep at least this many runs

        Returns:
            Number of runs deleted
        """
        cutoff = datetime.utcnow().timestamp() - (max_age_days * 86400)

        runs = []
        for run_dir in self._base_path.iterdir():
            if not run_dir.is_dir():
                continue

            metadata_path = run_dir / "metadata.json"
            if not metadata_path.exists():
                continue

            try:
                with open(metadata_path) as f:
                    metadata = json.load(f)
                created_at = datetime.fromisoformat(
                    metadata.get("created_at", datetime.utcnow().isoformat())
                ).timestamp()
                runs.append((created_at, run_dir.name))
            except Exception:
                continue

        # Sort by creation time (newest first)
        runs.sort(reverse=True)

        deleted = 0
        for i, (created_at, run_id) in enumerate(runs):
            # Keep minimum runs
            if i < keep_min_runs:
                continue

            # Delete if older than cutoff
            if created_at < cutoff:
                await self.delete_run(run_id)
                deleted += 1

        if deleted:
            logger.info(f"Cleaned up {deleted} old runs")

        return deleted
