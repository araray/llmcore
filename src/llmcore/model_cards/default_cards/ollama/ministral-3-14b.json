{
  "model_id": "ministral-3-14b",
  "display_name": "Ministral 3 14B",
  "provider": "mistral",
  "model_type": "chat",
  "architecture": {
    "family": "mistral",
    "parameter_count": "14B",
    "architecture_type": "transformer"
  },
  "context": {
    "max_input_tokens": 131072,
    "max_output_tokens": 8192
  },
  "capabilities": {
    "streaming": true,
    "function_calling": true,
    "tool_use": true,
    "json_mode": true,
    "structured_output": true,
    "vision": true,
    "reasoning": true
  },
  "pricing": null,
  "lifecycle": {
    "release_date": "2025-12-01",
    "knowledge_cutoff": "2025-05",
    "status": "active"
  },
  "license": "Apache-2.0",
  "open_weights": true,
  "aliases": ["Mistral-3-14B"],
  "description": "Ministral 3 14B is a compact open model offering best-in-class performance among models its size. It has 14 billion parameters and supports both text and vision input, enabling basic image analysis. The model is released under Apache 2.0 with instruction-tuned and reasoning variants available. With a native context length of 128K, Ministral 14B can handle fairly long documents and conversations. It achieves competitive results on reasoning tasks for its weight class (e.g. ~85% on AIME'25 math with a reasoning fine-tune). This model is ideal for edge deployments and applications needing a lighter model while still leveraging advanced capabilities like JSON outputs and tool integration.",
  "tags": ["open-weights", "edge", "vision"],
  "provider_mistral": {
    "license_type": "apache-2.0",
    "fill_in_middle": false
  },
  "source": "model_cards_01"
}
